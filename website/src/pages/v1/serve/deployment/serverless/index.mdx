import { Callout } from '@theguild/components'

# Serverless / On the Edge

Hive Gateway can be deployed on the edge. This means that you can deploy your Hive Gateway to a
serverless environment like AWS Lambda, Cloudflare Workers, or Azure Functions.

For Serverless environments, you cannot use Serve CLI `hive-gateway` but you can use the
`createGatewayRuntime` function from `@graphql-hive/gateway` package.

The serve configuration goes into `createGatewayRuntime` function instead of `gatewayConfig` export
in `gateway.config.ts` file.

## Distributed Caching

But you need to be aware of the limitations of these environments. For example, in-memory caching is
not possible in these environments. So you have to setup a distributed cache like Redis or
Memcached.

[See here to configure cache storage](/v1/serve/features/performance).

## Bundling problem

Hive Gateway cannot import the required dependencies manually, and load the supergraph from the file
system. So if you are not using a schema registry such as Hive Gateway or Apollo GraphOS, we need to
save the supergraph as a code file (`supergraph.js` or `supergraph.ts`) and import it.

### Loading the supergraph from a file

For example, in Mesh Compose you need to save the supergraph as a TypeScript file:

```ts filename="gateway.config.ts"
import { defineConfig } from '@graphql-mesh/compose-cli'

export const composeConfig = defineConfig({
  output: 'supergraph.ts',
  subgraph: [
    //...
  ]
})
```

In `supergraph.ts` file, you need to export the supergraph:

```ts
export default /* GraphQL */ `
  #...
`
```

Then you need to import the supergraph in your serverless function:

```ts
import { createGatewayRuntime, WSTransport } from '@graphql-hive/gateway'
// Let's say you are using WS transport
import supergraph from './supergraph.js'

const serveRuntime = createGatewayRuntime({
  supergraph,
  transports: {
    ws: WSTransport
  }
})
```
